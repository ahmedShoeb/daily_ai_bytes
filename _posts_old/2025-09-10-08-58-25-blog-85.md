---
layout: post 
title: Compute scaling will slow down due to increasing lead times
blog_url: https://epochai.substack.com/p/compute-scaling-will-slow-down-due?utm_source=tldrai 
---

## Overview

The article posits that the rapid pace of compute scaling, a key driver of AI progress since 2020, is expected to decelerate. This slowdown is attributed to rising economic uncertainties, longer development cycles for large-scale AI infrastructure (such as data centers and chip fabrication), and the increasing lead times required for these projects. Investors are likely to favor incremental scaling over massive upfront investments, further contributing to a slower rate of compute growth.

## Key Points

- Rapid compute scaling, a major factor in AI progress, is predicted to slow down.
- Increasing economic uncertainty and longer development cycles for AI infrastructure contribute to this deceleration.
- Lead times for acquiring GPUs, constructing data centers, and building fabs are significantly increasing.
- Investors are likely to opt for incremental scaling rather than massive upfront investments due to uncertain returns and enormous costs.
- The slowdown in compute scaling will likely impact AI progress by making algorithmic innovations harder to discover and decelerating training compute scaling.

## Key Topics Discussed

The article argues that the unprecedented compute scaling that has propelled AI advancements since 2020 is on the verge of slowing down. This deceleration is primarily due to growing economic uncertainties and the significantly extended lead times associated with developing large-scale AI infrastructure. The author breaks down these lead times into various components, including the acquisition of GPUs, which can take around half a year; the construction of data centers, ranging from one to three years for very large facilities; and the upgrading or building of new chip fabrication plants (fabs), which can take two to five years. The immense costs and uncertain returns of massive investments, exemplified by Sam Altman's $7 trillion infrastructure proposal, are pushing investors towards a more cautious, incremental scaling approach. This means that instead of a "YOLO scaleup," investments will be made in smaller chunks, with continuous reevaluation of returns, which inherently slows the overall pace. The implications for AI progress are substantial: fewer experiments can be run, novel algorithmic improvements become harder to discover, and the historical trend of rapid training compute scaling will likely decelerate. While some factors like political will or automation could potentially shorten lead times, the article maintains that a significant slowdown is inevitable, a dynamic it believes is currently underestimated in the AI community.

