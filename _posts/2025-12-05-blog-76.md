---
layout: post 
title: "RAPTOR: Autonomous Offensive/Defensive Research Framework"
blog_url: https://github.com/gadievron/raptor/?utm_source=tldrai 
---



## Key Points

RAPTOR is an autonomous offensive/defensive security research framework.
It is based on Claude Code and uses agentic workflows and automation for security research.
RAPTOR autonomously scans code with Semgrep and CodeQL, fuzzes binaries with AFL++, analyzes vulnerabilities with LLM reasoning, generates exploits, and proposes patches.
It integrates traditional security tools with agentic automation and analysis to understand code, prove exploitability, and suggest fixes.
The framework is open-source, modular, and extensible, welcoming community contributions.
It provides both an interactive Claude Code interface and a Python CLI for scripting and CI/CD integration.
RAPTOR includes pre-installed security tools like Semgrep, CodeQL CLI, AFL++, and rr debugger.
It offers specialized commands for various security testing phases, including static analysis, fuzzing, web security, and full autonomous workflows.
Exploit generation is supported, with best results observed using frontier models like Anthropic Claude, OpenAI GPT-4, or Gemini 2.5.

## Key Topics Discussed

Alright podcast listeners, get ready for a deep dive into something really cool for our cybersecurity folks out there! We're talking about RAPTOR, which stands for Recursive Autonomous Penetration Testing and Observation Robot. This isn't just any tool; it's an autonomous offensive and defensive security research framework, and it's built on Claude Code, bringing some serious agentic workflows and automation to the table. Developed by a team of brilliant minds including Gadi Evron, Daniel Cuthbert, Thomas Dullien, and Michael Bargury, RAPTOR is designed to supercharge your security research. What does it do, you ask? Well, it's pretty comprehensive! RAPTOR can autonomously scan your code using tools like Semgrep and CodeQL, validating dataflows as it goes. It also fuzzes your binaries with American Fuzzy Lop, analyzes vulnerabilities using advanced LLM reasoning, and get this, it can even generate proof-of-concepts for exploits and propose code patches to fix those vulnerabilities! It's like having a highly skilled security team working tirelessly for you, all wrapped up in one framework. RAPTOR really shines by combining those tried-and-true traditional security tools with cutting-edge agentic automation and analysis. It truly understands your code, proves exploitability, and suggests those all-important patches. Now, while the creators humbly call it a 'quick hack' and an 'early release,' they're incredibly proud of what they've built, and they've made it open-source, modular, and extensible, actively encouraging community contributions to make it even better. You can engage with RAPTOR in a couple of ways: either through its interactive Claude Code interface or via a Python command-line interface for scripting and CI/CD integration. Plus, it comes with a handy devcontainer that has all the prerequisites pre-installed, making setup a breeze. It's packed with pre-installed security tools like Semgrep, CodeQL CLI, AFL++, and the rr debugger. You'll find a range of commands for static code analysis, binary fuzzing, web application security testing, and even full autonomous workflows. And for those focused on exploit generation, it's noted that frontier models like Anthropic Claude, OpenAI GPT-4, or Gemini 2.5 deliver the best results. This project is a fantastic example of how AI can be leveraged for advanced security research, and it's definitely one to watch!

