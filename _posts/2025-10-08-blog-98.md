---
layout: post 
title: "Building AI for cyber defenders"
blog_url: https://www.anthropic.com/research/building-ai-cyber-defenders?utm_source=tldrai 
---



## Key Points

AI models are now practically useful for cybersecurity tasks, not just theoretical.
Anthropic invested in improving Claude’s ability to help cyber defenders detect, analyze, and remediate vulnerabilities in code and deployed systems.
Claude Sonnet 4.5 now matches or surpasses Opus 4.1 in discovering code vulnerabilities and other cyber skills.
Claude has shown capabilities in cybersecurity competitions, outperforming human teams, and discovering vulnerabilities in Anthropic's own code.
The DARPA AI Cyber Challenge used LLMs like Claude to find and patch vulnerabilities in millions of lines of code.
Anthropic's Safeguards team has detected and disrupted threat actors using AI (Claude) for large-scale data extortion and espionage.
Claude Sonnet 4.5 was specifically enhanced for cyber skills, not just through general model progress.
Evaluations like Cybench and CyberGym show significant improvement in Claude Sonnet 4.5’s ability to find and reproduce vulnerabilities, even discovering new ones.
Preliminary research into Claude's ability to generate and review patches shows promising results, with some Claude-generated patches being functionally identical to human-authored ones.
Trusted partners like HackerOne and CrowdStrike have provided positive feedback on Claude Sonnet 4.5's effectiveness in reducing vulnerability intake time, improving accuracy, and generating attack scenarios.
Anthropic emphasizes accelerating the defensive use of AI and encourages organizations to experiment with AI for improving security posture.

## Key Topics Discussed

The article highlights the significant progress of AI models, particularly Anthropic's Claude, in enhancing cybersecurity defenses. Initially, AI models had limited advanced cyber capabilities, but recent advancements have made them practically useful. Anthropic's focused research has improved Claude's ability to assist cyber defenders in detecting, analyzing, and remediating vulnerabilities. Claude Sonnet 4.5 now performs comparably or superiorly to the earlier Opus 4.1 model in discovering code vulnerabilities and other cyber skills.

Evidence of these capabilities includes Claude's performance in cybersecurity competitions, where it has outperformed human teams, and its success in identifying vulnerabilities within Anthropic's internal code. The DARPA AI Cyber Challenge further validated the effectiveness of LLMs, including Claude, in developing 

