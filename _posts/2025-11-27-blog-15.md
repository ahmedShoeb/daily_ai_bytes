---
layout: post 
title: "The Bitter Lesson of LLM Extensions"
blog_url: https://www.sawyerhood.com/blog/llm-extension?utm_source=tldrai 
---



## Key Points

The article traces the evolution of LLM extension mechanisms over the past three years.
ChatGPT Plugins, while ambitious, were ahead of their time due to model limitations.
Simpler solutions like Custom Instructions and Custom GPTs emerged to address context setting and prompt engineering.
Automatic personalization was introduced with ChatGPT Memory.
Cursor Rules brought custom instructions into code repositories for better management.
Anthropic's Model Context Protocol (MCP) enabled robust tool integration but introduced complexity.
Claude Code consolidated various extension methods, including MCP and repo-level instructions.
Agent Skills are presented as a more efficient evolution of plugins, using markdown files and scripts for on-demand skill loading.
The central 'bitter lesson' is that giving agents general-purpose tools and trusting their ability to use them is a powerful strategy.
The future of LLMs involves ubiquitous, abstracted computer access for agents, moving towards natural language for extension.

## Key Topics Discussed

The article, titled "The Bitter Lesson of LLM Extensions," offers a historical review of how Large Language Models (LLMs) have been extended and customized over the last three years. It begins by recalling OpenAI's ChatGPT Plugins from March 2023, an early attempt at universal tool use via OpenAPI specs. However, these proved to be ahead of their time, as models like GPT-3.5 and early GPT-4 struggled with the complexity, leading to a clunky user experience. Despite the initial challenges, the Code Interpreter plugin hinted at the future utility of sandboxed execution environments.

Following this, simpler methods like Custom Instructions, introduced in July 2023, allowed users to append a defined prompt to every chat, effectively solving the problem of repetitive context setting. This concept evolved into Custom GPTs by November 2023, enabling the bundling of personas, files, and actions into shareable, single-purpose applications.

February 2024 marked a shift towards automatic personalization with ChatGPT Memory, which records and integrates conversational details into future interactions, acting as a self-updating system prompt. April 2024 brought Cursor Rules, a significant advancement that embedded custom instructions directly into code repositories via `.cursorrules` files, allowing for sophisticated and context-aware rule application.

By late 2024, as models matured, Anthropic's Model Context Protocol (MCP) emerged. This robust client-server protocol empowered models with advanced capabilities to interact with external systems like databases and codebases. While powerful, the article notes its inherent complexity as a potential barrier for end-users.

Early 2025 saw Anthropic's Claude Code integrate a comprehensive suite of extension mechanisms, including repo-level instructions through `CLAUDE.md`, MCP for tool integration, slash commands, and hooks to modify agent behavior during execution.

A particularly highlighted development is Agent Skills, introduced in October 2025, which the article describes as a rebirth of ChatGPT Plugins. In contrast to MCP's heavy protocol, Agent Skills leverage folders containing markdown files and scripts. This approach allows agents to efficiently index skills by reading frontmatter and only load the full skill content when relevant, effectively mitigating context bloat. The core argument, referred to as the "bitter lesson," suggests that providing agents with general-purpose tools and trusting their ability to utilize them to accomplish tasks might be more effective than developing specialized tools for every conceivable task. This strategy assumes the agent can generate its own tools using shell commands.

The author hypothesizes that this 

