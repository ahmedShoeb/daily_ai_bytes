---
layout: post 
title: "ShinkaEvolve: Evolving New Algorithms with LLMs, Orders of Magnitude More Efficiently"
blog_url: https://sakana.ai/shinka-evolve/?utm_source=tldrai 
---



## Key Points

- ShinkaEvolve is an open-source evolutionary code optimization framework that discovers new algorithms with LLMs.
- It achieves unprecedented sample efficiency, outperforming traditional evolutionary approaches like AlphaEvolve.
- ShinkaEvolve was tested across four domains: Mathematical Optimization (Circle Packing), Agentic System Design (AIME Math Reasoning), Competitive Programming (ALE-Bench), and LLM Training Design (Mixture-of-Experts).
- In Circle Packing, it found a state-of-the-art solution using only 150 samples.
- For AIME Math Reasoning, it evolved a highly effective three-stage agent architecture.
- In Competitive Programming, it improved existing solutions, achieving significant performance boosts.
- For LLM Training Design, it discovered a novel load balancing loss function for Mixture-of-Experts models that outperformed state-of-the-art.
- ShinkaEvolve's efficiency stems from balancing exploration and exploitation, novelty-based program rejection sampling, and task-dependent Language Model Prioritization.
- The project is open-sourced with a technical report and GitHub repository.
- Sakana AI envisions ShinkaEvolve as a co-pilot for scientists and engineers, aiding in research and development.

## Key Topics Discussed

The article introduces ShinkaEvolve, an innovative open-source evolutionary code optimization framework developed by Sakana AI. Inspired by natural evolution and collective intelligence, ShinkaEvolve leverages Large Language Models (LLMs) to discover novel algorithms with remarkable sample efficiency, addressing a critical limitation of previous LLM-based evolutionary approaches like AlphaEvolve, which often require thousands of attempts to find solutions. ShinkaEvolve was rigorously tested across four distinct domains, demonstrating its power, generality, and efficiency. In mathematical optimization, specifically the 26-circle packing problem, it discovered a new state-of-the-art solution using only 150 samples. For agentic system design, it evolved a highly effective three-stage architecture for solving challenging AIME Math competition problems. In competitive programming, ShinkaEvolve significantly improved existing solutions for NP-Hard optimization problems. Furthermore, in the domain of LLM training design, it discovered a novel load balancing loss function for Mixture-of-Experts (MoE) models, outperforming state-of-the-art methods and improving efficiency and accuracy. The framework's unprecedented sample efficiency is attributed to three key innovations: a program parent sampling technique that balances exploration and exploitation, novelty-based program rejection sampling to avoid evaluating minor variations, and a bandit-based strategy for task-dependent Language Model Prioritization, dynamically selecting the best LLM from an ensemble. Sakana AI has open-sourced ShinkaEvolve, providing a technical report and a GitHub project, and encourages its use by the community. The company envisions ShinkaEvolve as an easy-to-use companion tool for scientists and engineers, accelerating discovery across various scientific and engineering problems, with potential future extensions to generate its own problems and assess solutions in broader domains like medicine and design.

