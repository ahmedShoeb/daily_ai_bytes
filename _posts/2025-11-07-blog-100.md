---
layout: post 
title: "Code Execution with MCP"
blog_url: https://www.anthropic.com/engineering/code-execution-with-mcp?utm_source=tldrai 
---



## Key Points

The Model Context Protocol (MCP) is an open standard for connecting AI agents to external systems, replacing custom integrations with a universal protocol.
Growing MCP adoption leads to challenges like excessive token consumption from tool definitions and intermediate results, increasing costs and slowing agents.
Code execution with MCP improves efficiency by presenting servers as code APIs, allowing agents to load only necessary tools and process data within the execution environment.
This approach significantly reduces token usage (e.g., 98.7% saving) and enhances context efficiency.
Key benefits include progressive disclosure of tools, context-efficient data processing, more powerful control flow, privacy-preserving operations, and state persistence for reusable skills.
However, code execution introduces complexities such as the need for secure sandboxed environments, resource limits, and monitoring, which add operational overhead and security considerations.

## Key Topics Discussed

Hey everyone! Today we're diving into a really interesting development from Anthropic: how code execution is making AI agents smarter and more efficient when interacting with external systems through the Model Context Protocol, or MCP. Traditionally, connecting AI agents to various tools and data sources has been a bit of a custom headache, requiring unique integrations for every single pairing. But MCP, launched in November 2024, is changing that by providing a universal standard. Think of it as a common language that allows agents to effortlessly integrate with a vast ecosystem of tools.

While MCP has seen rapid adoption, scaling up brings its own set of challenges. When agents are connected to hundreds or even thousands of tools, two major issues pop up: tool definitions start to overload the agent's context window, and intermediate results from tool calls consume a ton of extra tokens. Both of these problems slow down agents and rack up costs. Imagine an agent trying to sift through hundreds of thousands of tokens just to understand what tools are available before it can even process a request!

That's where code execution comes in as a game-changer. Instead of agents making direct tool calls, MCP servers are now presented as code APIs. This means agents can write actual code to interact with these servers. The beauty of this approach is that agents only load the tool definitions they need for a specific task, and they can process large datasets within the execution environment before sending a refined result back to the model. This leads to dramatic reductions in token usageâ€”we're talking about savings of up to 98.7% in some cases!

The benefits extend beyond just token efficiency. Code execution allows for what they call 'progressive disclosure' of tools, where agents can explore and load tool definitions on-demand, much like navigating a file system. It also makes tool results much more context-efficient; instead of passing entire spreadsheets, agents can filter and transform data in code, sending only the relevant bits back to the model. Plus, complex logic like loops, conditionals, and error handling can be handled directly in code, making for more robust and efficient control flows. There are even privacy advantages, as intermediate results stay within the execution environment, preventing sensitive data from ever reaching the model's context. And for even higher security, sensitive data can be tokenized at the MCP client level. Finally, agents can maintain state across operations and even save their own code as reusable 'skills,' building a powerful library of capabilities over time.

Now, it's not all sunshine and rainbows. Implementing code execution does add complexity. You need a secure, sandboxed environment for running agent-generated code, complete with resource limits and monitoring. So, while the benefits in terms of cost reduction, lower latency, and better tool composition are huge, these implementation costs need to be carefully considered. But overall, it's a massive step forward in making AI agents more powerful and adaptable. If you're working with MCP, Anthropic encourages you to explore code execution and share your findings with the community!

