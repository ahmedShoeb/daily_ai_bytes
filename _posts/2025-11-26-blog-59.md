---
layout: post 
title: "Insights on AI Intelligence, GPT Evolution, and Attention Mechanism"
blog_url: https://threadreaderapp.com/thread/1991910395720925418.html?utm_source=tldrai 
---



## Key Points

Animal intelligence is optimized for survival, self-preservation, and social dynamics, leading to 'general' intelligence.
LLM intelligence is optimized for statistical simulation of human text, task-specific rewards, and user engagement, resulting in 'spiky' capabilities.
GPT4.5, with 10X more pretraining compute than GPT4, shows subtle, diffuse improvements in non-reasoning tasks (EQ-related) but not significant leaps in reasoning.
The 'attention' operator, crucial for Transformers, was independently conceived, inspired by human cognitive processes in translation.
Tokenizers, a separate LLM pipeline stage using algorithms like Byte Pair Encoding, are responsible for many LLM behaviors and problems.
Historical predictions, like Licklider's 1960 vision of intelligence amplification, highlight the complementary strengths of humans and computers, now evolving with LLMs' implicit thinking.
The future of prompt engineering may involve 'AutoGPTs' that chain GPT calls into programs, requiring awareness of GPTs' inherent limitations.

## Key Topics Discussed

This article presents a multi-faceted discussion on artificial intelligence, contrasting animal and large language model (LLM) intelligence, exploring the evolution of GPT models, revealing the origins of the "attention" mechanism, detailing the role of tokenizers, revisiting historical AI predictions, and envisioning the future of prompt engineering.

The author begins by highlighting the fundamental differences in optimization pressures between animal and LLM intelligences. Animal intelligence is shaped by natural selection for survival, self-preservation, and social interaction, leading to broad, general capabilities. In contrast, LLM intelligence is primarily optimized for statistical text simulation, task-specific rewards, and user engagement, resulting in a more "spiky" and task-dependent performance.

A significant portion of the discussion is dedicated to the perceived release and performance of GPT4.5. The author, having had access to GPT4.5, notes that while it represents a 10-fold increase in pretraining compute over GPT4, the improvements are subtle and diffuse. These enhancements are observed in areas less reliant on explicit reasoning, such as world knowledge, creativity, analogy-making, and humor (EQ-related tasks), rather than substantial advancements in reasoning-heavy domains like math or coding.

The article also delves into the fascinating origin story of the "attention" operator, a cornerstone of the Transformer neural network architecture. Through personal email correspondence with one of its authors, Dzmitry Bahdanau, it's revealed that the concept, inspired by how humans "attend" to parts of a source sentence during translation, was developed independently and was a "differentiable and data-dependent weighted average." The author emphasizes the brilliance and impact of attention as a major unlock in neural network design, acknowledging that "Attention is All You Need" popularized it by focusing solely on this mechanism.

Further technical insights are provided regarding tokenizers, which are described as a distinct stage in the LLM pipeline with their own training sets and algorithms like Byte Pair Encoding (BPE). The author notes that many of the peculiar behaviors and limitations of LLMs can be traced back to the tokenization process, suggesting that its eventual removal would be ideal.

The discussion then broadens to a historical perspective, referencing J.C.R. Licklider's 1960 vision of computing as an "intelligence amplification" tool. Licklider's observations on the complementary strengths of humans and computers—with machines handling rote tasks and humans focusing on "thinking"—have largely held true for decades. However, the advent of LLMs, with their implicit, statistical "thinking" capabilities, is now making a significant dent in this paradigm.

Finally, the article touches upon the future of prompt engineering, proposing the concept of "AutoGPTs" as the next frontier, where multiple GPT calls are chained together to form programs. The author also highlights a crucial psychological difference between humans and GPTs: LLMs are inherently unaware of their own strengths and limitations, such as finite context windows or challenges with mental math, which necessitates explicit consideration in effective prompting.

Overall, the thread offers a rich tapestry of current AI understanding, historical context, and forward-looking speculation, emphasizing the unique nature of synthetic intelligence compared to its biological counterpart.

