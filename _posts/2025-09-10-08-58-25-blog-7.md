---
layout: post 
title: Donâ€™t Build An AI Safety Movement
blog_url: https://writing.antonleicht.me/p/dont-build-an-ai-safety-movement?utm_source=tldrai 
---

## Overview

The article argues against building a popular AI safety movement, suggesting it could be counterproductive by undermining organic public support, associating credible organizations with extreme views, and diluting safety-specific goals with broader political issues. It advocates for elite-focused expert advocacy and authentic opposition to specific policies as more effective strategies.

## Key Points

- Building a popular AI safety movement risks undermining existing organic public support.
- It may lead to credible AI safety organizations being associated with perceived crackpot protesters.
- Broad movements can be captured by adjacent political causes, diluting safety goals.
- Authentic opposition to specific policies and elite-focused expert advocacy are presented as more effective.
- A badly executed movement could hurt both popular support and elite-focused advocacy by reducing credibility.

## Key Topics Discussed

The author contends that efforts to create a popular AI safety movement are likely to be more detrimental than beneficial. They argue that such a movement could diminish the credibility of existing, genuine public support for AI safety by making it appear coordinated rather than grassroots. Furthermore, it risks linking respected AI safety organizations with more extreme or politically motivated groups, thus damaging their reputation. The article suggests that broad popular movements often get sidetracked by related political issues like labor concerns, environmental protection, or anti-tech sentiment, which can dilute the core mission of AI safety. Instead, the author advocates for strategies that have proven effective, such as focused expert advocacy and organic public opposition to specific policies. They highlight that the changing nature of AI technology and policy needs makes it difficult for a popular movement to maintain consistent and relevant demands, potentially leading to outdated or misguided proposals. The piece also warns that an incubated movement could provide ammunition for opponents of AI safety and erode the trust that policymakers place in public sentiment regarding AI regulation. Ultimately, the author advises funders and credible organizations to disassociate from movement-building efforts, emphasizing that AI safety's strengths lie in its latent authentic political support and high expert-level credibility, which could be jeopardized by a broad, undiscipled popular movement.

