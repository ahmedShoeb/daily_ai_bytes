---
layout: post 
title: "Andrej Karpathy's Reflections on AI: AGI, LLMs, Attention, and the Future of Agents"
blog_url: https://threadreaderapp.com/thread/1979644538185752935.html?utm_source=tldrai 
---



## Key Points

- Andrej Karpathy discusses his AGI timeline predictions, which are more pessimistic than current hype but still optimistic from a broader perspective, emphasizing remaining work for true AGI.
- He uses the 'Animals vs. Ghosts' analogy, suggesting LLMs are 'ghost-like' due to pre-packaged intelligence from internet data, distinct from evolutionarily 'pre-packaged' animal intelligence.
- Karpathy critiques Reinforcement Learning (RL) for its inefficiency and noise, advocating for alternative learning paradigms like 'agentic interaction' and 'system prompt learning.'
- He talks about the 'cognitive core' idea, focusing on stripping down LLMs to improve generalization rather than relying on memorization.
- Karpathy shares the origin story of the 'attention' mechanism in neural networks, clarifying its initial introduction by Bahdanau et al. before the Transformer paper.
- He provides insights into the release of GPT-4.5, noting subtle but diffuse improvements in 'EQ-related' tasks, like creativity and understanding, rather than reasoning.
- Karpathy critiques the overshooting of tooling in LLM agents, advocating for collaborative AI tools rather than fully autonomous ones that generate vast amounts of unsupervised code.
- He touches on job automation, citing radiologists' success, and the complementary strengths of humans and computers, with LLMs now impacting 'thinking' tasks.

## Key Topics Discussed

Hey podcast listeners! We've got a fascinating dive today into the world of AI with Andrej Karpathy's insightful reflections, stemming from a recent podcast appearance and a collection of his thoughts. Karpathy kicks things off by offering his perspective on AGI timelines. He's somewhere in the middle – a bit more cautious than some of the current hype, but still quite optimistic compared to the skeptics. He really stresses that while LLMs have made incredible strides, there's still a mountain of work to do, from integration to safety, before we see true AGI that can handle just about any human job.He then brings up this super cool 'Animals vs. Ghosts' analogy. He argues that LLMs are more like 'ghosts,' their intelligence pre-packaged from the vastness of internet data, which is quite different from the evolutionary pre-packaging we see in animal intelligence. The goal, he suggests, is to eventually make these LLMs more 'animal-like.'Karpathy doesn't shy away from critiquing Reinforcement Learning, or RL. He finds it inefficient and noisy, and he's really pushing for new learning paradigms like 'agentic interaction' and 'system prompt learning' to drive future AI advancements. He also revisits his 'cognitive core' concept for LLMs, emphasizing the need to strip them down to improve generalization, moving beyond just memorization.We also get a fascinating history lesson on the 'attention' mechanism in neural networks. Karpathy clarifies its origins, giving credit to Dzmitry Bahdanau and his colleagues for introducing it before the famous Transformer paper. He even shares an email from Bahdanau detailing the inspiration behind this pivotal development.When it comes to the latest tech, Karpathy shares his observations on GPT-4.5. He notes that while it's definitely an improvement thanks to more pretraining compute, the enhancements are subtle. He sees them mainly in what he calls 'EQ-related' tasks – things like creativity and understanding nuance, rather than pure reasoning. He anticipates that further training with RL will be key to boosting its reasoning capabilities.Finally, Karpathy offers a thoughtful critique of the current push for fully autonomous LLM agents. He's concerned that the industry might be getting ahead of itself. Instead, he advocates for a collaborative approach, where humans and LLMs work together. He wants LLMs to explain their reasoning, ask questions when unsure, and provide code in manageable chunks, rather than just spitting out huge, unsupervised blocks of code. He also touches on job automation, pointing out how LLMs are now starting to impact 'thinking' tasks, a role traditionally reserved for humans. He concludes with a nod to the importance of physics education for cognitive development and his thoughts on the future of prompt engineering with 'AutoGPTs.'

