---
layout: post 
title: "NVIDIA Blackwell Platform Dramatically Reduces AI Inference Costs with 10x Improvement in Tokenomics"
blog_url: https://blogs.nvidia.com/blog/inference-open-source-models-blackwell-reduce-cost-per-token/?utm_source=tldrai 
---



## Key Points

NVIDIA's Blackwell platform reduces AI inference costs by up to 10x compared to previous Hopper systems
Tokenomics (cost per token) is crucial for scaling AI applications across healthcare, gaming, and customer service industries
Inference providers Baseten, DeepInfra, Fireworks AI, and Together AI use NVIDIA Blackwell to host advanced open source models
Sully.ai in healthcare reduced inference costs by 90% and returned over 30 million minutes to physicians using Baseten's Model API
Gaming company Latitude achieved 4x cost reduction per token using DeepInfra's Blackwell platform
Sentient Labs saw 25-50% cost efficiency improvements for complex multi-agent workflows with Fireworks AI
Decagon reduced customer service voice AI costs by 6x and achieved sub-second response times using Together AI
NVIDIA's extreme codesign across compute, networking, and software drives these dramatic cost savings
The upcoming NVIDIA Rubin platform promises another 10x reduction in token costs over Blackwell

## Key Topics Discussed

NVIDIA is driving down AI inference costs dramatically with its Blackwell platform, helping companies reduce token costs by up to 10x compared to previous Hopper systems. The article explains how tokenomics - essentially the cost per token - is critical for scaling AI applications across industries, with recent MIT research showing infrastructure and algorithmic efficiencies reducing inference costs for frontier-level performance by up to 10x annually. Several AI inference providers including Baseten, DeepInfra, Fireworks AI, and Together AI are using NVIDIA Blackwell to host advanced open source models that have reached frontier-level intelligence. Healthcare company Sully.ai achieved a 90% reduction in inference costs using Baseten's Model API with open source models on NVIDIA Blackwell GPUs, returning over 30 million minutes to physicians previously lost to data entry. Gaming company Latitude reduced cost per token by 4x using DeepInfra's Blackwell-powered platform, allowing them to handle traffic spikes while maintaining fast response times for AI-powered gaming experiences. Sentient Labs saw 25-50% better cost efficiency for their complex multi-agent workflows using Fireworks AI's inference platform on Blackwell, successfully handling 5.6 million queries in a week during a viral launch. Customer service company Decagon achieved 6x cost reductions and sub-second response times using Together AI's production inference on NVIDIA Blackwell for their voice AI stack. NVIDIA's extreme codesign across compute, networking, and software layers enables these dramatic cost savings, with the upcoming Rubin platform promising another 10x reduction in token costs over Blackwell.

