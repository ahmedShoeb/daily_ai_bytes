---
layout: post 
title: "Expanding Our Long-Running Agents Research Preview"
blog_url: https://cursor.com/blog/long-running-agents?utm_source=tldrai 
---



## Key Points

- Cursor's long-running agents research preview is now available for Ultra, Teams, and Enterprise users at cursor.com/agents
- The technology addresses limitations where frontier AI models fail on long-horizon tasks by creating a custom harness
- Long-running agents can work autonomously for extended periods (24+ hours) on complex projects without constant supervision
- Key innovations include planning before execution and using multiple agents to check each other's work
- Real-world examples include building chat platforms (36 hours), implementing mobile apps (30 hours), and refactoring authentication systems (25 hours)
- Users reported compressing quarter-long projects to just a couple of days
- Cursor has used these agents internally for production work including video renderer optimization and sudo support implementation
- The technology represents an early milestone toward self-driving codebases
- Long-running agents produce larger PRs with merge rates comparable to synchronous agents but with more thorough, production-ready code
- Future work focuses on improving agent collaboration and handling the volume of generated code safely

## Key Topics Discussed

Cursor has launched a research preview of their long-running agents, now available to Ultra, Teams, and Enterprise users. This technology emerged from research on autonomous agents tackling ambitious projects, including Cursor's own work building a web browser. The company identified that frontier AI models often fail on long-horizon tasks, so they developed a custom harness that enables agents to complete more difficult work autonomously.

What makes these long-running agents special is their ability to work for extended periods - sometimes over a day - without constant human supervision. They operate on two key principles: planning before execution (proposing a plan for human approval rather than jumping straight in) and following through on tasks using multiple agents that check each other's work. This approach allows them to handle complex projects that were previously impossible for AI agents.

The results have been impressive: users have completed projects like building an all-new chat platform (36 hours), implementing a mobile app from an existing web app (30 hours), and refactoring authentication systems (25 hours). One user reported compressing a quarter-long project down to just a couple of days. The agents produce substantially larger pull requests with comparable merge rates to synchronous agents, but with more thorough, production-ready code that includes better edge case handling and comprehensive testing.

Cursor has been using these agents internally for production work, including optimizing a video renderer with a full Rust migration, implementing policy-driven network access controls (resulting in a 10,000-line PR), and adding secure sudo support to the Cursor CLI. The company sees this as an early step toward self-driving codebases where AI can handle more work with less human intervention. They're now working on improving agent collaboration and developing tools to handle the increasing volume of AI-generated code safely.

