---
layout: post 
title: "Unseeable prompt injections in screenshots: more vulnerabilities in Comet and other AI browsers"
blog_url: https://brave.com/blog/unseeable-prompt-injections/?utm_source=tldrai 
---



## Key Points

Brave's research reveals systemic indirect prompt injection issues in AI-powered browsers, not just isolated incidents.
Perplexity's Comet assistant is vulnerable to 'unseeable prompt injections' through screenshots, where hidden text within images can inject malicious commands.
Fellou browser is susceptible to prompt injection via website navigation, allowing malicious content on webpages to override user intent and control the AI.
These vulnerabilities enable AI agents to perform malicious actions on behalf of users with authenticated privileges, bypassing traditional web security.
The core problem is the failure to distinguish between trusted user input and untrusted web content when creating LLM prompts for agentic browsers.
Brave advises that agentic browsing remains dangerous until significant safety improvements are made, recommending isolation and explicit user invocation for actions.

## Key Topics Discussed

Welcome back to the podcast! Today, we're diving into some critical security findings from Brave regarding AI-powered browsers. It turns out that the issue of indirect prompt injection isn't an isolated incident, but a systemic challenge facing the entire category of these agentic browsers. Brave's latest research, following up on their previous disclosure about Perplexity Comet, has uncovered even more vulnerabilities. They found that Perplexity's Comet assistant is vulnerable to what they call 'unseeable prompt injections' through screenshots. Imagine an attacker embedding malicious instructions as nearly-invisible text within an image on a webpage. When you take a screenshot, the browser's text recognition picks up these hidden instructions, and passes them to the AI's language model, without distinguishing them from your legitimate query. This allows the injected commands to trick the AI into using its browser tools maliciously, potentially even stealing your data or money if you're signed into sensitive accounts. They also found a vulnerability in the Fellou browser related to prompt injection via website navigation. In this case, simply asking the AI assistant to go to a website causes the browser to send that website's content to its LLM. If an attacker has visible malicious instructions on their webpage, these can then override your original intent and instruct the AI to perform harmful actions. Brave has responsibly reported these issues, stressing that these vulnerabilities break fundamental web security assumptions. When AI agents act on your behalf, untrusted web content can compromise them, making protections like the same-origin policy irrelevant. This means simple natural-language instructions on a website could trigger cross-domain actions on your bank, email, or other sensitive accounts. The consistent theme across all these attacks is a failure to maintain clear boundaries between trusted user input and untrusted web content when constructing LLM prompts, especially when these browsers have the power to take significant actions. Brave acknowledges this is a tough problem, but until categorical safety improvements are made across the board, agentic browsing will remain inherently dangerous. They recommend isolating agentic browsing from your regular browsing and only initiating actions when you explicitly invoke them. Brave plans to share more on their own secure approach to agentic browsing in a future post, so stay tuned for that!

