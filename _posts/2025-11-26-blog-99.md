---
layout: post 
title: "LLM Council: A System for Multi-LLM Querying and Consensus"
blog_url: https://github.com/karpathy/llm-council?utm_source=tldrai 
---



## Key Points

The LLM Council is a local web application that leverages OpenRouter to query multiple large language models simultaneously.
The process involves three key stages: individual LLMs provide initial responses, followed by a review stage where LLMs anonymously rank each other's outputs for accuracy and insight.
Finally, a designated 'Chairman LLM' synthesizes all responses into a single, comprehensive answer for the user.
The project was developed as a 'fun Saturday hack' to explore side-by-side LLM evaluation and cross-model opinions.
It is provided 'as is' for inspiration, without ongoing support, encouraging users to modify it as they wish.
Setup requires an OpenRouter API key and configuration of participating LLM models and the Chairman model in `backend/config.py`.

## Key Topics Discussed

Alright folks, today we're diving into a super interesting project from Karpathy called the 'LLM Council'! Imagine this: instead of just asking one of your favorite large language models like GPT, Gemini, or Claude a question, you can now send that query to a whole council of them. This is a local web app that essentially acts like a supercharged ChatGPT, but with a twist. It uses OpenRouter to dispatch your query to multiple LLMs, then it gets those LLMs to review and even rank each other's responses, and finally, a 'Chairman LLM' takes all that input and crafts the ultimate answer for you. Here's how it breaks down: First, all the LLMs get your query and give their initial thoughts. You can actually see each of their individual responses in a neat tab view. Then comes the cool part: each LLM is shown the responses from the *other* LLMs. The identities are kept secret so they can't play favorites, and they're asked to rank each other's work based on accuracy and insight. Finally, the chosen Chairman LLM takes all these different perspectives and reviews, and puts together one final, comprehensive response. This whole project was a fun hack, developed to explore and evaluate various LLMs side-by-side, especially in scenarios like reading books with AI. It's incredibly useful to see multiple viewpoints and how each LLM critiques the others. Karpathy is providing this as-is for inspiration, encouraging everyone to play around with it and make it their own, rather than providing ongoing support. To get it running, you'll need an OpenRouter API key and you can customize your council by editing the `backend/config.py` file to include your preferred LLMs and designate your Chairman model. Pretty neat, right?

