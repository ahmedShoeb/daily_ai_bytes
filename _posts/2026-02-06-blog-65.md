---
layout: post 
title: "DeepSeek claims its reasoning model outperforms OpenAI's o1 on certain benchmarks"
blog_url: https://techcrunch.com/2025/01/20/deepseek-claims-its-reasoning-model-beats-openais-o1-on-certain-benchmarks/ 
---



## Key Points

- DeepSeek, a Chinese AI startup, has announced a new reasoning model called **DeepSeek-R1** that it claims outperforms OpenAI's **o1** model on specific benchmarks.
- The **DeepSeek-R1** model is described as a 'reasoning-first' model, meaning it prioritizes logical and step-by-step problem-solving over raw speed or breadth of knowledge.
- DeepSeek claims its model achieves **87.1%** on the **MT-Bench**, a popular benchmark for evaluating reasoning capabilities, compared to OpenAI's o1, which scored **86.7%**.
- On the **HumanEval** benchmark, DeepSeek-R1 scored **91.0%**, while OpenAI's o1 scored **88.8%**.
- The company also mentions that its model excels in areas like **math, coding, and complex logical tasks**, where step-by-step reasoning is critical.
- DeepSeek is positioning itself as a competitor in the AI reasoning space, targeting developers and researchers who prioritize accuracy and logical consistency.
- The startup was founded in **2023** and has been making waves in the AI community with its focus on reasoning models.
- OpenAI's o1 model was announced in **November 2024** and is designed to be faster and more capable than its predecessors, including **GPT-4**.
- DeepSeek's announcement comes as AI companies continue to push boundaries in **model performance, efficiency, and specialization**.
- The company is likely aiming to attract attention in both **academic and commercial AI sectors**, especially in regions where OpenAI's models may not be as accessible.

## Key Topics Discussed

Hey everyone, welcome back to the podcast! Today, we’re diving into some exciting news from the AI world. DeepSeek, a Chinese AI startup that’s been gaining traction since its founding in 2023, just dropped a bold claim: their new reasoning model, **DeepSeek-R1**, outperforms OpenAI’s highly anticipated **o1** model on certain benchmarks. That’s right—DeepSeek is saying their model is better in specific areas, and it’s sparking some serious conversation in the AI community.

Now, let’s talk about what this means. DeepSeek-R1 is what they call a **'reasoning-first'** model. Unlike some of its competitors that focus on raw speed or sheer breadth of knowledge, DeepSeek-R1 is all about **logical problem-solving**. It’s designed to break down complex tasks into smaller, manageable steps and deliver more accurate, step-by-step solutions. This approach is particularly valuable in fields like **math, coding, and complex logical reasoning**, where precision and methodical thinking are key.

The benchmarks they’re referencing are pretty telling. On **MT-Bench**, a popular test for reasoning capabilities, DeepSeek-R1 scored **87.1%**, just slightly edging out OpenAI’s o1, which scored **86.7%**. That’s a close race, but in the world of AI, even a small margin can be huge. Then there’s **HumanEval**, where DeepSeek-R1 really shines with a **91.0%** score, compared to OpenAI’s o1 at **88.8%**. These numbers suggest that DeepSeek’s model might be particularly strong when it comes to **coding and problem-solving tasks** that require a bit more finesse.

OpenAI’s o1 model was introduced back in **November 2024** and is part of their push to create faster, more capable AI systems. It’s designed to outperform models like **GPT-4**, which was already a powerhouse in the industry. But here’s the twist: DeepSeek isn’t just competing with OpenAI—they’re also positioning themselves as a strong alternative in regions where OpenAI’s models might not be as accessible or widely used.

This announcement is part of a broader trend we’re seeing in AI, where companies are specializing their models to excel in particular areas—whether it’s reasoning, creativity, or efficiency. DeepSeek’s focus on **reasoning-first** models could appeal to developers, researchers, and businesses that prioritize **accuracy and consistency** over sheer speed or versatility.

So, what’s next for DeepSeek? They’re likely looking to make some noise in both the **academic and commercial AI sectors**. This kind of benchmark competition is great for pushing innovation and could lead to even more impressive advancements in how AI models tackle complex problems. And let’s not forget, this is all happening in a landscape where AI is evolving at lightning speed, with new models and capabilities popping up all the time.

We’ll keep an eye on how this plays out, especially as more companies enter the fray. Could this be the start of a new wave in AI reasoning models? Stay tuned, because this story is far from over!

