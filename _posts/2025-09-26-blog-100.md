---
layout: post 
title: "OpenAI API Updates: New Models, Webhooks, and Prompt Management"
blog_url: https://threadreaderapp.com/thread/1970535239048159237.html?utm_source=tldrai 
---



## Key Points

- Post-trained o3 and o4-mini models are now used for deep research in ChatGPT.
- These models support MCP (search/fetch) and Code Interpreter.
- Webhooks are introduced for API event notifications, recommended for long-horizon tasks to enhance reliability.
- A new Prompt object enables central management, versioning, and optimization of prompts across Playground, API, Evals, and Stored Completions.
- The Playground now features an 'Optimize' button for prompts and allows users to save, reuse, and share prompts and their configurations.
- Tools and Structured Outputs can now be utilized and evaluated in eval runs, supporting OpenAI-hosted, MCP, and non-hosted tools.

## Key Topics Discussed

OpenAI has released several updates to its API, focusing on enhancing model capabilities, improving task reliability, and streamlining prompt management. The post-trained o3 and o4-mini models, which power deep research in ChatGPT, now also support MCP (search/fetch) and Code Interpreter. To improve reliability for long-horizon tasks, webhooks have been introduced, allowing users to receive notifications for various API events such as completed responses and batch jobs. A significant addition is the new Prompt object, which facilitates central management, versioning, and optimization of prompts across the Playground, API, Evals, and Stored Completions, eliminating the need for manual copying. The Playground has also seen improvements, including an 'Optimize' button to refine prompts for the API and the ability to save and share prompt configurations. Furthermore, eval runs now support the use and evaluation of tools and Structured Outputs, encompassing OpenAI-hosted, MCP, and non-hosted tools, with evaluations based on arguments passed and responses returned.

