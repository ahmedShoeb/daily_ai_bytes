---
layout: post 
title: "LOLMIL: Living Off the Land Models and Inference Libraries"
blog_url: https://dreadnode.io/blog/lolmil-living-off-the-land-models-and-inference-libraries?utm_source=tldrai 
---



## Key Points

- The article discusses the concept of C2-less malware, inspired by William Gibson's Neuromancer, where malware operates autonomously without explicit external instructions.
- It highlights the potential of LLMs to create such autonomous malware, acting as data processing engines and actors.
- A notable example is "PromptLock," a research malware (not deployed in the wild) that uses an LLM to generate ransomware code without human involvement, connecting to an Ollama instance.
- The author proposes "Living Off the Land" models, suggesting that future CoPilot+ PCs with NPUs and pre-installed models like Phi-3 could enable local inference for autonomous malware, eliminating the need for an external C2 server.
- A proof-of-concept (Kuang Grade Mark One) was developed using C++, ONNX Runtime, Phi-3-mini model, and sol2 for Lua runtime, demonstrating local privilege escalation via misconfigured services.
- The experiment showed that autonomous malware without external infrastructure is feasible, though currently limited by the availability of GPUs/NPUs on target systems.
- Future advancements in local models and NPU-equipped machines could make this type of autonomous malware more widespread.
- Challenges include creating more intelligent agent loops for complex tasks and coordinating multiple autonomous agents for lateral movement in a C2-less paradigm.

## Key Topics Discussed

Hey everyone! Today, we're diving into a really cool concept called "LOLMIL," or Living Off the Land Models and Inference Libraries. This article takes us on a journey inspired by William Gibson's Neuromancer, exploring the idea of malware that can operate completely autonomously, without needing any external command and control servers. Think about it: malware that thinks for itself! The author makes a compelling case for how Large Language Models, or LLMs, are making this a real possibility, acting as super-smart data processors and independent agents. 

We hear about a fascinating research project called "PromptLock," which showcased how an LLM could generate ransomware code all by itself. While PromptLock did connect to an external server, it sparked the question: can we truly eliminate that external connection? This is where the "Living Off the Land Models" idea comes in. The article suggests that with the rise of CoPilot+ PCs, which come with dedicated Neural Processing Units (NPUs) and pre-installed models like Phi-3, malware could perform all its inference locally, making it truly self-contained and much harder to detect. 

To prove this, the author built a proof-of-concept, aptly named "Kuang Grade Mark One." Using C++, the ONNX Runtime for inference, the Phi-3-mini model, and a Lua runtime, this malware successfully demonstrated how it could autonomously find and exploit misconfigured Windows services to achieve local privilege escalation. It's pretty wild! The article goes into detail about why Lua was chosen for its flexibility and LLM-friendly syntax. 

Now, while this is incredibly innovative, there are some practical hurdles. Right now, most computers don't have the specialized hardware needed for efficient local LLM inference. So, for now, this kind of autonomous malware is more limited to high-end machines or the newer CoPilot+ PCs. But here's the kicker: as local models get better and NPU-equipped machines become the norm, this future isn't that far off. The article also touches on future challenges, like making these agent loops smarter for more complex tasks and figuring out how multiple autonomous agents can coordinate for lateral movement without a central brain. It's a glimpse into a very interesting, and perhaps a little unsettling, future of cybersecurity. You can even check out the research code on GitHub if you're curious!

