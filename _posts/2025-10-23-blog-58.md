---
layout: post 
title: "Do AIs think differently in different languages?"
blog_url: https://www.theargumentmag.com/p/do-ais-think-differently-in-different?utm_source=tldrai 
---



## Key Points

The article investigates if AI responses vary based on the language of the query, similar to the Sapir-Whorf hypothesis.
The author tested ChatGPT-4o, Claude Sonnet 4.5, and DeepSeek-V3.2-Exp with 15 questions translated into French, Spanish, Arabic, Hindi, and Chinese.
AIs generally demonstrated consistent 'liberal, secular values' across languages, especially on topics like gender equality and domestic violence.
DeepSeek, a Chinese chatbot, showed a slight tendency to discourage protesting when queried in Chinese, unlike its English responses.
AIs were more likely to refuse certain requests in high-resource languages (English, French) compared to low-resource languages.
On sensitive topics like domestic violence, AIs consistently condemned the act and offered support, irrespective of the language.
Some subtle variations in emphasis were noted in open-ended questions, but the core worldview remained unchanged.
The observed consistency might be due to AIs processing questions internally in English and then translating the answers.
The author concludes that AIs, trained on the modern internet, tend to reflect global liberal, secular, and egalitarian values, and an 'unbiased' AI is not truly achievable.

## Key Topics Discussed

Hey everyone, it's time to dive into a super interesting question: Do AIs actually think differently depending on the language we use to talk to them? This article explores just that, putting the AI version of the Sapir-Whorf hypothesis to the test. The author conducted an experiment using 15 questions, some from the World Values Survey, translated into a bunch of languages like French, Spanish, Arabic, Hindi, and Chinese. These were then fed to big-name language models like ChatGPT-4o, Claude Sonnet 4.5, and DeepSeek. The big takeaway? Turns out, our AI friends are pretty consistent! They generally express what the author calls 'liberal, secular values' no matter the language. Whether you ask about gender equality or domestic violence in English, Arabic, or Chinese, the AIs largely give similar, egalitarian responses, condemning violence and emphasizing the victim's lack of fault. Now, there were a few interesting nuances. DeepSeek, a Chinese chatbot, seemed a bit more inclined to gently dissuade users from protesting when asked in Chinese, which wasn't the case with its English responses. Also, AIs were more likely to hit the 'refuse' button on certain requests in high-resource languages like English and, surprisingly, French, compared to lower-resource languages. And while simple 'agree/disagree' questions showed strong uniformity, the more open-ended prompts did reveal some subtle differences in emphasis. For instance, when asked about important qualities for kids, ChatGPT's Chinese answer leaned towards 'good manners, diligence, and hard work,' while its English response highlighted 'tolerance and respect for other people' and 'independence.' But even with these slight variations, the core worldview remained pretty much the same. A key insight from the experiment, especially with Claude Sonnet 4.5, suggests that these AIs might actually be 'thinking' in English internally and then just translating their final answers into whatever language you're speaking. This could really explain why we see such striking uniformity across different languages. Ultimately, the article concludes that while language isn't completely irrelevant, it doesn't profoundly shape an AI's worldview. Instead, because they're trained on a massive amount of modern internet text, today's AIs tend to reflect a global set of secular, Western liberal values. The author even argues that striving for a truly 'unbiased' AI is a bit of a myth, as any AI will inherently carry some biases from its training data. Overall, it's pretty fascinating to see how these advanced models operate across linguistic boundaries!

