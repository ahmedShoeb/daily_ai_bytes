---
layout: post 
title: "Building a design tool with GPT-5.3-Codex: What 25 hours of uninterrupted coding looks like"
blog_url: https://developers.openai.com/cookbook/examples/codex/long_horizon_tasks?utm_source=tldrai 
---



## Key Points

- OpenAI's GPT-5.3-Codex was tested in a 25-hour uninterrupted experiment to build a design tool from scratch, using ~13M tokens and generating ~30k lines of code
- The experiment demonstrates Codex's ability to handle long-horizon coding tasks with key capabilities: following specs, staying on task, running verification, and repairing failures autonomously
- The real shift in AI coding is about time horizon - agents can now stay coherent for longer durations, complete larger work chunks end-to-end, and recover from errors without losing context
- Codex operates through a disciplined agent loop: Plan → Edit code → Run tools (tests/build/lint) → Observe results → Repair failures → Update docs/status → Repeat
- Key success factors included durable project memory using markdown files for specs, plans, implementation instructions, and documentation
- Codex ran verification at every milestone (tests, lint, typecheck) and repaired failures before continuing, not just writing code and hoping it worked
- The agent implemented significant features including canvas editing, live collaboration, inspector controls, layers management, history snapshots, replay timeline, and export functionality
- The experiment represents a shift toward long-running AI teammates that can handle substantial work end-to-end with humans steering at milestones rather than micromanaging
- OpenAI's Codex app now includes native plan mode and features like parallel threads, skills, automations, and Git worktrees for production use
