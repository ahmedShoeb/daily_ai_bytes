---
layout: post 
title: LLMs as Parts of Systems
blog_url: https://brooker.co.za/blog/2025/08/12/llms-as-components.html?utm_source=tldrai 
---

## Overview

This article advocates for integrating Large Language Models (LLMs) as components within larger, carefully designed systems, rather than treating them as standalone solutions. It argues that combining LLMs with traditional computational tools like code interpreters, databases, or SMT solvers unlocks capabilities that LLMs alone cannot achieve, often more cheaply and efficiently, while aligning with the "Bitter Lesson" of AI research.

## Key Points

LLMs are more powerful and efficient when used as components in larger systems.
Combining LLMs with tools (e.g., code interpreters, SMT solvers) enables capabilities unachievable by LLMs alone.
These integrated systems can perform tasks orders of magnitude more cheaply and quickly.
The argument aligns with Rich Sutton's "Bitter Lesson," emphasizing general methods that leverage computation.
The goal is to enable AI agents to "discover" by giving them access to computational tools, not by encoding human thought processes.
Examples include simple Python snippets for string manipulation and Amazon Bedrock's Automated Reasoning Checks using LLMs with SMT solvers.

## Key Topics Discussed

The article, titled "LLMs as Parts of Systems," argues for a paradigm shift in how Large Language Models (LLMs) are viewed and deployed. Instead of considering LLMs as isolated, all-encompassing solutions, the author emphasizes their true potential when integrated as components within more extensive, carefully designed computational systems. This perspective suggests that while LLMs possess impressive standalone capabilities, their power, dependability, efficiency, and flexibility are significantly amplified when combined with other specialized tools. The core argument is that systems built with LLMs and other computational tools can achieve feats that LLMs alone cannot, and often at a substantially lower cost and greater speed. The author draws a parallel to a simple task like counting characters in a string; while a powerful LLM *could* do it, a system incorporating an LLM to generate a Python snippet and a code interpreter to execute it would be orders of magnitude more cost-effective and faster. This seemingly trivial example illustrates a fundamental principle: a robust system is greater than the sum of its individual components, leveraging decades of progress in algorithms and computational methods. A more advanced example cited is Amazon Bedrock's Automated Reasoning Checks. Here, LLMs are utilized for their strength in extracting facts and rules from natural language, while Satisfiability Modulo Theories (SMT) solvers are employed for their precision in logical reasoning and formal justification. This combination allows for capabilities like verifying logical consistency that current generation LLMs cannot perform independently. The author stresses that the hype surrounding LLMs often overshadows this critical point, leading to a misconception that LLMs should be self-sufficient. The article also addresses Rich Sutton's influential "Bitter Lesson" in AI research, which posits that general methods leveraging computation are ultimately the most effective, and that building in human-like thought processes is not sustainable in the long run. The author contends that viewing LLMs as components within systems is entirely consistent with Sutton's lesson. The idea is not to encode *how* humans think into these systems, but rather to equip AI agents with access to the powerful computational tools and discoveries that computer science has accumulated over decades. By making tools like Python, SMT solvers, and other algorithms available to AI agents, they gain significant leverage and new capabilities, enabling them to "discover" rather than merely reflecting what has already been discovered. This outlook makes it an "exciting time to be a systems person," as LLMs present a potent new component for building even more capable systems with novel functionalities.

