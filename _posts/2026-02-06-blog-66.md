---
layout: post 
title: "Qwen2.5-1M: Alibaba’s Open-Source AI Model Now Handles 1 Million Tokens"
blog_url: https://qwenlm.github.io/blog/qwen2.5-1m/ 
---



## Key Points

- QwenLM has released **Qwen2.5-1M**, its first open-source models capable of processing **1 million tokens** in context—Qwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M.
- The new **inference framework**, built on vLLM and optimized with sparse attention, processes 1M-token inputs **3x to 7x faster** than before.
- A **technical report** details the training and inference techniques, including progressive context expansion, length extrapolation with **Dual Chunk Attention (DCA)**, and sparse attention optimizations.
- The models **outperform their 128K-token counterparts** in long-context tasks, especially beyond 64K tokens, and even **beat GPT-4o-mini** in some long-context benchmarks.
- Short-context performance remains **unchanged**, ensuring core capabilities like reasoning and instruction-following are preserved.
- **DCA** enables models trained on shorter contexts (like 32K tokens) to achieve near-perfect accuracy in passkey retrieval tasks with 1M-token contexts—**no additional training needed!**
- The **sparse attention mechanism** reduces VRAM usage by **96.7%** when processing long sequences, making deployment more efficient.
- Local deployment requires **120GB+ VRAM** for the 7B model and **320GB+ VRAM** for the 14B model, but you can still use them for shorter tasks if resources are limited.
- Qwen Chat, an advanced AI assistant, also leverages Qwen2.5-Turbo’s **1M-token context support**, enabling multi-tool interactions like coding, searching, and image generation.
- Future improvements will focus on **more efficient training and inference methods**, broader deployment options, and even better performance in long-context scenarios.

## Key Topics Discussed

Hey everyone! If you're into AI and love pushing the boundaries of what these models can do, you’re gonna want to hear about this. Alibaba’s QwenLM team has just dropped something massive: **Qwen2.5-1M**, their first open-source AI models capable of handling **1 million tokens** in context. That’s right—1 million! And they’re not just stopping at the models; they’ve also open-sourced the inference framework to make it easier for developers to deploy and use these powerful tools efficiently and at scale, especially for long-context tasks like document analysis or extended conversations with the AI assistant, Qwen Chat, which we’ll get to in a bit.

