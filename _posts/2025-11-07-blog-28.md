---
layout: post 
title: "Coding Agents Are Outliers"
blog_url: https://vivekhaldar.com/articles/coding-agents-are-outliers/?utm_source=tldrai 
---



## Key Points

Coding agents are outliers in AI agent development due to unique characteristics of programming.
Programming offers deterministic outputs, clear success/failure states, rich tooling, and immediate feedback loops.
The overlap between AI model builders (programmers) and users creates a strong feedback loop for improving coding agents.
Programming is exceptionally well-represented in LLM training data, covering the entire software development lifecycle.
The article distinguishes between 'workflows' and true 'agents,' with coding agents falling into the latter category due to their planning and reasoning abilities.
A major challenge for agents in other domains is the 'tacit knowledge problem,' where crucial expert knowledge is unwritten.
The success of coding agents has created unrealistic expectations for AI agents in other fields, which often lack programming's clear-cut, feedback-rich environment.

## Key Topics Discussed

Alright folks, today we're diving into an insightful article by Vivek Haldar titled 'Coding Agents Are Outliers.' This piece really makes us think about why AI coding agents, despite all the buzz and their impressive capabilities, are actually quite unique in the grand scheme of AI agent development. Haldar argues that the secret sauce behind their success lies in the inherent nature of programming itself. Think about it: coding has super clear outcomes—either it works or it doesn't! You get immediate feedback, there are tons of robust tools like debuggers and profilers, and measuring success is pretty straightforward. These are conditions that simply aren't present in most other fields.

One of the most fascinating points is the tight feedback loop between the builders of these AI models and their users. Since the AI researchers and developers are themselves programmers, they're the first to use and 'dogfood' their own creations. This direct, continuous feedback helps refine and improve the models at an incredible pace. Plus, the sheer volume of high-quality programming data available online—from code repositories to technical documentation and tutorials—provides an unparalleled training ground for large language models, covering not just the code, but the entire software development process.

Haldar also draws a crucial distinction between 'workflows,' which are predefined steps, and true 'agents,' which can actually reason, plan, and adapt their approach. Coding agents, with their ability to improvise solutions to complex problems, definitely fall into the 'agent' category. However, the article highlights a significant hurdle for AI agents in other specialized domains: the 'tacit knowledge problem.' Unlike programming, where much of the knowledge is written down, many fields rely on unarticulated, intuitive knowledge held by experts, which is incredibly difficult to extract and codify for AI. So, while coding agents offer a glimpse into what's possible, we need to temper our expectations for AI agents in other areas, as the unique conditions that fuel coding agent success are rarely replicated elsewhere. It's a fantastic read that truly reshapes our understanding of AI agent development!

