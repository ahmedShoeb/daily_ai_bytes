---
layout: post 
title: Online RL for Cursor Tab
blog_url: https://cursor.com/en/blog/tab-rl?utm_source=tldrai 
---

## Overview

Cursor Tab, a system that predicts users' next actions in their codebase, has been improved using online reinforcement learning. This approach involves frequently rolling out new models and using the resulting user interaction data for continuous training. The new model boasts a 28% higher accept rate with 21% fewer suggestions.

## Key Points

- Cursor Tab predicts users' next coding actions.
- It's improved using online reinforcement learning.
- New models are rolled out frequently, trained on fresh user data.
- The new model has a 28% higher accept rate and 21% fewer suggestions.
- The approach addresses the problem of noisy suggestions by optimizing a 'policy' directly.

## Key Topics Discussed

The article 'Online RL for Cursor Tab' details how Cursor has leveraged online reinforcement learning (RL) to significantly enhance its Tab model, a system designed to predict users' next actions within their codebase. Unlike traditional methods that rely on static datasets or infrequent model updates, Cursor's approach involves continuously deploying new model checkpoints to users and using the real-time interaction data for immediate training. This rapid feedback loop allows the model to learn and adapt quickly. The core innovation lies in defining a reward function that encourages accepted suggestions while penalizing unaccepted ones, effectively training the model to target a specific acceptance rate (e.g., 25%). This policy gradient method enables the Tab model to inherently learn when to suggest and when to refrain, leading to more relevant and less distracting assistance. The results are compelling: the new Tab model exhibits a 28% higher accept rate while making 21% fewer suggestions. This not only improves user productivity by providing more accurate and timely assistance but also addresses the challenge of 'noisy' suggestions that can disrupt a developer's workflow. The article emphasizes the importance of on-policy data and the infrastructure required to facilitate such a fast iteration cycle in AI development.

