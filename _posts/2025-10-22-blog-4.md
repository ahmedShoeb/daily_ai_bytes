---
layout: post 
title: "We are in the \"gentleman scientist\" era of AI research"
blog_url: https://www.seangoedecke.com/ai-and-informal-science/?utm_source=tldrai 
---



## Key Points

Historically, many scientific discoveries were made by amateurs before professional scientists existed.
Modern scientific fields often require extensive specialized knowledge, but AI research is currently in an 'early days' phase.
AI research discoveries, despite complex mathematical presentations, can be deceptively simple, often trivial in code.
Many impactful AI ideas are not new but are older concepts successfully applied to Large Language Models (LLMs) for the first time.
The success of LLMs has created numerous 'easy' scientific questions, making AI research accessible to hobbyists and professional researchers alike.
Examples like Anthropic's 'skills' and Recursive Language Models demonstrate how simple ideas can lead to significant AI advancements.
Informal user experimentation, reminiscent of 17th-century 'gentleman science,' is crucial for uncovering unknown AI capabilities.
The author advocates for more informal research, particularly in enhancing LLMs' ability to generate novel ideas.

## Key Topics Discussed

Alright podcast listeners, get ready to dive into a fascinating idea: according to this article, we're currently living in the 'gentleman scientist' era of AI research! Think about it – historically, many groundbreaking scientific discoveries were made by curious amateurs, not just professional academics. The article highlights that in the early days of any science, discoveries are often simple and observation-based. Fast forward to today, and fields like modern physics are incredibly complex, requiring years of specialized study. But AI, the author argues, is different; it's still in its scientific infancy. What's really interesting is how many AI discoveries, despite looking intimidating with all their complex math, are actually deceptively simple at their core—ideas that could be expressed in just a few lines of code. The article points out that many 'big ideas' in AI aren't brand new either; they're often older concepts that are suddenly incredibly effective when applied to Large Language Models, or LLMs, for the very first time. The author uses a great analogy, comparing the success of LLMs to a 'rubber-band engine' revolution. Just like that, the transformative power of LLMs, stemming from a relatively straightforward concept, has opened up a whole new realm of 'easy' scientific questions. This makes AI research accessible not just to the pros but also to hobbyists and curious minds, just like those early gentleman scientists. The article even gives examples like Anthropic's 'skills' and Recursive Language Models, showing how simple implementations can lead to really useful advancements. It emphasizes that this kind of informal, user-driven experimentation is vital because the full capabilities of these powerful LLMs are still largely unknown. So, if you've ever thought about tinkering with AI, now might just be your time to shine, as the author encourages more informal research, especially in pushing LLMs to come up with new ideas. It's a call to action for the curious, suggesting that some of the most exciting breakthroughs might still come from unexpected places!

