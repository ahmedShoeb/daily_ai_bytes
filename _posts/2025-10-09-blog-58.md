---
layout: post 
title: "How weâ€™re securing the AI frontier"
blog_url: https://blog.google/technology/safety-security/ai-security-frontier-strategy-tools/?utm_source=tldrai 
---



## Key Points

- AI presents both new threats from bad actors and a powerful advantage for cyber defenders.
- Google is launching CodeMender, an AI-powered agent that automatically fixes critical code vulnerabilities using Gemini models.
- CodeMender performs root cause analysis and self-validates patches before human sign-off.
- A new, dedicated AI Vulnerability Reward Program (AI VRP) is being introduced to incentivize security researchers for finding and reporting high-impact AI-related flaws.
- The AI VRP unifies reward tables and clarifies reporting for AI security and abuse issues.
- Google is updating its Secure AI Framework to SAIF 2.0 to address risks posed by autonomous AI agents.
- SAIF 2.0 includes an agent risk map and principles for securing AI agents: human controllers, limited powers, and observability.
- Google is actively collaborating with partners like DARPA and CoSAI to advance AI security across the industry.

## Key Topics Discussed

Google acknowledges the dual nature of AI, recognizing its potential as both an unprecedented attack tool for cybercriminals and a transformative asset for cyber defense. To counter emerging threats and leverage AI for good, Google is implementing several new initiatives. One significant development is CodeMender, an AI-powered agent utilizing Gemini models to automatically identify and fix critical code vulnerabilities. CodeMender employs sophisticated methods for root cause analysis and autonomously generates and self-validates patches, streamlining the security process across open-source landscapes.
Furthering its commitment to security research, Google is launching a dedicated AI Vulnerability Reward Program (AI VRP). This program aims to expand collaboration with the global security research community by providing a clear and comprehensive set of rules and reward tables for AI-related issues, simplifying reporting, and maximizing incentives for discovering high-impact flaws. The AI VRP unifies previously separate abuse and security reward tables, offering greater clarity for researchers.
Moreover, Google is enhancing its Secure AI Framework (SAIF) to SAIF 2.0, specifically addressing the rapidly evolving risks associated with autonomous AI agents. SAIF 2.0 introduces new guidance on agent security risks and mitigation controls, supported by an agent risk map. It emphasizes three core principles for Google's own agents: ensuring well-defined human controllers, carefully limiting agent powers, and making their actions and planning observable. Google also donates SAIF's risk map data to the Coalition for Secure AI Risk Map initiative, contributing to industry-wide AI security advancements. Through these proactive tools and strong partnerships with public and private entities like DARPA and the Coalition for Secure AI, Google is dedicated to fundamentally shifting the balance of cybersecurity in favor of defenders, securing the cutting edge of technology for a safer world.

