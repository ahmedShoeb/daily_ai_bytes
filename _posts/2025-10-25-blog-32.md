---
layout: post 
title: "ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory"
blog_url: https://arxiv.org/abs/2509.25140?utm_source=tldrai 
---



## Key Points

ReasoningBank is a novel memory framework designed for large language model agents.
It learns generalizable reasoning strategies from an agent's self-judged successful and failed experiences.
Agents use retrieved memories to inform interactions and integrate new learnings, enabling continuous improvement.
Memory-aware test-time scaling (MaTTS) accelerates and diversifies this learning by scaling up interaction experience.
ReasoningBank consistently outperforms existing memory mechanisms across web browsing and software engineering benchmarks.
MaTTS further amplifies these gains, establishing memory-driven experience scaling as a new dimension for agent self-evolution.

## Key Topics Discussed

Hey everyone, today we're diving into a super interesting paper about how AI agents can get smarter over time! Researchers have introduced something called **ReasoningBank**, a new memory framework for large language model agents. You know how sometimes AI agents just forget what they've learned and keep making the same mistakes? Well, ReasoningBank solves that by distilling powerful reasoning strategies from both their wins and losses. This means when an agent encounters a new task, it can pull up relevant memories to guide its actions and then integrate what it learns back into its knowledge base. Talk about continuous improvement! 

But wait, there's more! They've also developed **Memory-aware Test-Time Scaling, or MaTTS**. This cool technique supercharges the learning process by giving the agent more compute for each task, leading to richer, more diverse experiences. This creates a fantastic synergy: better memories lead to more effective scaling, and vice-versa. The results are pretty impressive too. Across web browsing and software engineering tasks, ReasoningBank blows other memory systems out of the water, and MaTTS just makes it even better. This really opens up a new dimension for how agents can self-evolve and develop some truly emergent behaviors. Pretty exciting stuff for the future of AI!

