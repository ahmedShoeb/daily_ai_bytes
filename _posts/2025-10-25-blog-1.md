---
layout: post 
title: "Statement on Superintelligence"
blog_url: https://superintelligence-statement.org/?utm_source=tldrai 
---



## Key Points

Many leading AI companies aim to build superintelligence, raising concerns.
Risks include human obsolescence, disempowerment, loss of freedom, and potential extinction.
The statement calls for a prohibition on superintelligence development.
Prohibition should only be lifted with broad scientific consensus on safety and strong public buy-in.
The statement has garnered 17,016 signatures, including 5,000 from a related petition by Ekō.

## Key Topics Discussed

Alright everyone, let's talk about something pretty significant. We're looking at a statement regarding superintelligence, and it's certainly food for thought. While we're seeing some amazing innovations in AI that could bring about incredible health and prosperity, there's a growing movement expressing serious concerns. Many top AI companies are openly stating their goal to develop superintelligence in the coming decade – that's AI that can essentially outperform humans on almost all cognitive tasks. This ambition has sparked a range of worries, from the very real possibility of human economic obsolescence and a sense of disempowerment, to the loss of our freedoms, civil liberties, and even control. There are also national security risks and, for some, the terrifying prospect of human extinction. This particular statement is designed to create common ground among experts and public figures who are against rushing into the development of superintelligence. It explicitly calls for a complete prohibition on its development, and here's the kicker: this ban shouldn't be lifted until there's both a broad scientific consensus that it can be done safely and controllably, and strong public buy-in. Currently, this statement has gathered over 17,000 signatures, showing a significant number of people are taking these concerns very seriously.

