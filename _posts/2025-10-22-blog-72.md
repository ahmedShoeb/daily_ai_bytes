---
layout: post 
title: "Alibaba Cloud claims to slash Nvidia GPU use by 82% with new pooling system"
blog_url: https://www.scmp.com/business/article/3329450/alibaba-cloud-claims-slash-nvidia-gpu-use-82-new-pooling-system?utm_source=tldrai 
---



## Key Points

- Alibaba Cloud introduced a new computing pooling system called Aegaeon.
- The system reportedly cut Nvidia GPU usage by 82% for AI models.
- Aegaeon reduced the need for Nvidia H20 GPUs from 1,192 to 213 to serve dozens of models up to 72 billion parameters.
- It was beta-tested for over three months in Alibaba Cloud's model marketplace.
- Research on Aegaeon was presented at the 31st Symposium on Operating Systems Principles (SOSP) in Seoul.
- The system aims to address resource inefficiency where a small number of popular models lead to underutilized GPUs for other models.
- Alibaba Cloud CTO Zhou Jingren is among the paper's authors.

## Key Topics Discussed

Hey podcast listeners! Get ready for some big news from the world of AI! Alibaba Cloud is making headlines with their new computing pooling solution, Aegaeon, which they claim has dramatically slashed the number of Nvidia GPUs needed for their artificial intelligence models by a whopping 82%! This is a game-changer! Imagine, during its three-month beta test in Alibaba Cloud's model marketplace, Aegaeon brought down the requirement for Nvidia H20 GPUs from 1,192 to just 213, while still efficiently serving numerous large language models, some packing up to 72 billion parameters. That's some serious optimization! The details of this innovative system were shared in a research paper at the 31st Symposium on Operating Systems Principles in Seoul, South Korea. Alibaba Cloud's Chief Technology Officer, Zhou Jingren, was even one of the co-authors. This system is designed to tackle a common problem in cloud services: the inefficiency where a few popular AI models hog resources, leaving many expensive GPUs sitting idle for models that are only occasionally used. Aegaeon helps solve this by making GPU power more efficient, allowing a single GPU to cater to multiple models. This means big savings on hardware costs and a much smarter way to manage AI workloads. Definitely something to keep an eye on as AI continues to evolve!

