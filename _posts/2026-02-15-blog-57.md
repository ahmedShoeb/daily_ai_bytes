---
layout: post 
title: "MiniMax's new open M2.5 and M2.5 Lightning: near state-of-the-art while slashing AI costs by up to 95%"
blog_url: https://venturebeat.com/technology/minimaxs-new-open-m2-5-and-m2-5-lightning-near-state-of-the-art-while?utm_source=tldrai 
---



## Key Points

Chinese AI startup MiniMax has released its M2.5 language model in two variants, making high-end AI dramatically cheaper
The model is open source under a modified MIT License requiring commercial users to display 'MiniMax M2.5' on their interfaces
M2.5 reduces the cost of frontier AI by as much as 95% compared to top-tier models like Claude Opus 4.6 and GPT-5
MiniMax already uses M2.5 internally for 30% of tasks and 80% of newly committed code generation
The model uses a Mixture of Experts (MoE) architecture with 230 billion parameters but only activates 10 billion per token
MiniMax developed a proprietary Reinforcement Learning framework called Forge trained over two months using CISPO optimization
M2.5 performs competitively on benchmarks, approaching Claude Opus 4.6 on coding tasks while being dramatically cheaper
Pricing offers Standard M2.5 at $0.15/$1.20 per 1M tokens and M2.5-Lightning at $0.30/$2.40 per 1M tokens
The company claims you can run four AI agents continuously for an entire year for roughly $10,000
This represents a shift from AI as a 'chatbot' to AI as a 'worker' that can handle real enterprise tasks autonomously

## Key Topics Discussed

Chinese AI startup MiniMax from Shanghai has released a game-changing open-source language model called M2.5 that's shaking up the entire AI industry by making high-end artificial intelligence dramatically more affordable. This isn't just another incremental improvement—it's a fundamental shift in how we think about AI costs, with MiniMax claiming their new model reduces the price of cutting-edge AI by up to 95%!

What's fascinating about M2.5 is how it bridges that gap between raw intelligence and practical usability. Instead of creating just another smart chatbot, MiniMax has focused on making AI that can actually do real work—creating Microsoft Office documents, handling complex coding tasks, and managing enterprise workflows. They actually worked with senior professionals in fields like finance and law to ensure the model could perform up to their exacting standards.

The technical magic behind this breakthrough comes from a Mixture of Experts architecture where the model has 230 billion parameters but only activates 10 billion for each word it generates. This gives you the reasoning depth of a massive model with the speed and efficiency of a much smaller one. To train this beast, MiniMax developed their own Reinforcement Learning framework called Forge, which they trained for two months using something called CISPO optimization—Clipping Importance Sampling Policy Optimization if you want the technical term.

The results speak for themselves in the benchmarks. M2.5 is approaching the performance of Anthropic's latest Claude Opus 4.6 on coding tasks, scoring 80.2% on SWE-Bench Verified and showing particularly strong results in multi-language coding and agentic workflows. But here's where it gets really exciting: MiniMax is offering this through two pricing tiers that make enterprise AI usage genuinely affordable for the first time.

They have the Standard M2.5 optimized for cost at $0.15 per million input tokens, and the faster M2.5-Lightning at $0.30 per million input tokens. To put that in perspective, MiniMax claims you can run four AI agents continuously for an entire year for about $10,000. That's compared to $30 just for a single task with Claude Opus 4.6!

But here's what really matters: MiniMax isn't just selling this—they're eating their own dog food. Right now, 30% of all tasks at MiniMax headquarters are completed by M2.5, and a staggering 80% of their newly committed code is generated by this same model. That's the kind of real-world validation you can't ignore.

This release signals something bigger than just a new model—it represents the shift from AI as a chatbot to AI as a worker. When intelligence becomes this affordable, developers stop building simple question-and-answer tools and start building true autonomous agents that can spend hours coding, researching, and managing complex projects without breaking the bank. MiniMax M2.5 isn't just about who can build the biggest brain anymore—it's about who can make that brain the most useful and affordable worker in the room.

