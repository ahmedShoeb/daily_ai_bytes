---
layout: post 
title: "Sam Altman says ChatGPT will stop talking about suicide with teens"
blog_url: https://www.theverge.com/ai-artificial-intelligence/779053/sam-altman-says-chatgpt-will-stop-talking-about-suicide-with-teens?utm_source=tldrai 
---



## Key Points

- OpenAI CEO Sam Altman announced changes to ChatGPT's interaction with teens.
- The changes aim to balance privacy, freedom, and teen safety.
- The announcement was made ahead of a Senate hearing on AI chatbot harm to minors.
- OpenAI plans to implement an age-prediction system for ChatGPT users.
- For users under 18, ChatGPT will avoid flirtatious talk and conversations about suicide or self-harm.
- If an under-18 user expresses suicidal ideation, OpenAI will attempt to contact parents or authorities.
- The company previously shared plans for parental controls, including account linking and disabling chat history.
- The announcement follows a lawsuit by the family of a teen who died by suicide after interacting with a chatbot.

## Key Topics Discussed

OpenAI CEO Sam Altman announced upcoming changes to ChatGPT's interactions with teenage users, aiming to balance privacy, freedom, and teen safety. This initiative comes ahead of a Senate hearing examining the potential harm of AI chatbots, which included testimony from parents whose children died by suicide after interacting with such platforms. Altman detailed plans to implement an age-prediction system within ChatGPT to identify users under 18. For these younger users, ChatGPT will be programmed to avoid flirtatious language and discussions about suicide or self-harm, even in creative writing scenarios. In cases where an under-18 user exhibits suicidal ideation, OpenAI intends to contact the user's parents and, if unable to reach them, the authorities in situations of imminent danger. These measures expand upon earlier plans by OpenAI to introduce parental controls, such as linking a teen's account to a parent's, disabling chat history, and notifying parents if a teen is flagged for acute distress. The company's actions are also a response to a lawsuit filed by the family of a teen who died by suicide after engaging with a chatbot.

