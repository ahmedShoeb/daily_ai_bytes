---
layout: post 
title: "Designing agentic loops"
blog_url: https://simonwillison.net/2025/Sep/30/designing-agentic-loops/?utm_source=tldrai 
---



## Key Points

Coding agents like Anthropic's Claude Code and OpenAI's Codex CLI can directly exercise code, correct errors, and run experiments, making LLMs more useful for code production.
A critical new skill is designing 'agentic loops,' where an LLM agent runs tools in a loop to achieve a defined goal.
YOLO mode, where commands are approved by default, is dangerous due to risks like bad shell commands, data exfiltration, and using the machine as a proxy for attacks.
To run agents safely in YOLO mode, it's recommended to use secure sandboxes like Docker, Apple container tool, or GitHub Codespaces, or other platforms that run code on remote machines.
When designing agentic loops, agents are proficient at running shell commands and can install packages; an `AGENTS.md` file can provide command examples.
Credentials should be tightly scoped, ideally for test/staging environments with budget limits, to minimize potential damage.
Agentic loops are particularly effective for problems with clear success criteria that involve trial and error, such as debugging, performance optimization, dependency upgrades, and optimizing container sizes.
The effectiveness of coding agents is significantly amplified by a robust and clean test suite.
Designing agentic loops is a very new skill, with Claude Code being released in February 2025, highlighting the fresh and evolving nature of this field.

## Key Topics Discussed

The article discusses the emerging skill of 'designing agentic loops' for coding agents like Anthropic's Claude Code and OpenAI's Codex CLI. These agents represent a significant leap in LLM utility for code generation, as they can execute code, fix errors, and conduct experiments. The core concept of an LLM agent is its ability to run tools in a continuous loop to achieve a specific objective. A key consideration is the use of 'YOLO mode,' where commands are automatically approved. While this mode enhances productivity, it poses significant risks, including unintended data manipulation, data exfiltration, and the misuse of the machine as a proxy for attacks. To mitigate these dangers, the article strongly advocates for running agents in secure sandboxes, such as Docker, Apple's new container tool, or GitHub Codespaces, or by leveraging services that execute code on remote infrastructure. When configuring agentic loops, it's advised to focus on providing shell commands, which agents handle effectively, and to use a guide like an `AGENTS.md` file for command examples. Furthermore, issuing tightly scoped credentials, ideally for non-production environments with strict budget limits, is crucial for security. Agentic loops are best suited for problems with clear success criteria that often involve iterative trial and error, such as debugging, optimizing performance, upgrading dependencies, or shrinking container sizes. A recurring theme for maximizing the value of these agents is the presence of a robust and cleanly passing test suite. The article concludes by emphasizing that designing agentic loops is a very new and evolving skill, underscoring the ongoing development in the field of AI agents.

