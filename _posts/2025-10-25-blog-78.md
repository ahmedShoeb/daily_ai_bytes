---
layout: post 
title: "Epoch AI Estimates OpenAI's Cloud Compute Spending for 2024"
blog_url: https://epoch.ai/data-insights/openai-compute-spend?utm_source=tldrai 
---



## Key Points

Epoch AI estimates OpenAI's 2024 cloud compute spending to be around $6 billion, comprising $3 billion for training, $1.8 billion for inference, and $2 billion for research.
OpenAI relied on cloud providers for its compute resources in 2024, not owning significant AI compute infrastructure.
The analysis focused on estimating the final training costs for key OpenAI models released or announced between Q1 2024 and Q1 2025, including GPT-4.5, GPT-4o, and Sora Turbo.
Estimates for GPT-4.5's cloud spending were based on cluster size, training duration, and cost per GPU-hour.
For other models, costs were derived from estimated floating-point operations (FLOP) and standardized GPU utilization/cost assumptions.
These figures are estimates from investor documents and projections, and while other evidence supports their approximate correctness, they are not completely reliable.
OpenAI's reported substantial unprofitability in 2024 aligns with its high compute spending, indicating compute forms a major part of its costs.
The $1.8 billion inference expense likely excludes Microsoft's spending on licensed OpenAI models for its own products.

## Key Topics Discussed

Hey everyone, let's dive into some fascinating insights from Epoch AI about OpenAI's cloud compute spending in 2024. This report gives us a breakdown of how much OpenAI is estimated to have shelled out for its essential AI operations. According to Epoch's analysis, OpenAI's overall cloud compute expenses for 2024 are projected to be substantial, with an estimated $3 billion going towards training, $1.8 billion for inference, and another $2 billion allocated for research compute, amortized over two years. It's important to note that OpenAI didn't own significant amounts of AI compute in 2024; they primarily relied on cloud companies for these critical resources. The report also delves into the final training costs for some of OpenAI's significant models released or announced between Q1 2024 and Q1 2025. This includes models like GPT-4.5, GPT-4o, the o3 December preview, and Sora Turbo. For GPT-4.5, Epoch AI estimated its cloud spending by looking at factors like cluster size, duration of training, and the cost per GPU-hour. For other models, a simpler approach was taken, estimating their training compute in floating-point operations, or FLOP, and then calculating the cloud cost based on standardized assumptions about GPU utilization and hourly GPU costs. Now, a crucial point to remember is that these figures are estimates. They are drawn from documents shared with investors in September 2024 and presented to journalists, and they do include projections for the final quarter of 2024. So, while other evidence suggests these overall spending figures are approximately correct, they shouldn't be considered 100% reliable. The report highlights that OpenAI made around $3.7 billion in revenue in 2024 but is widely reported to be substantially unprofitable. This aligns with the estimated $6 billion in compute spending, especially if compute forms the majority of their overall costs. Interestingly, the $1.8 billion in inference expenses likely doesn't cover Microsoft's spending on running licensed OpenAI models for its own products, such as Copilot and the Azure API. This report truly underscores the massive investment required in AI development today!

